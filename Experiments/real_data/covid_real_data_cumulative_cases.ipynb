{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFhy95XbZqOS",
        "outputId": "15f8f3ad-9634-4cce-8309-4665b077fb7f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "import torch.nn as nn\n",
        "from numpy import genfromtxt\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd \n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "torch.manual_seed(1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "NJ-EItw9leO0",
        "outputId": "cd0e4812-098a-4659-dc08-e48e687a98fd"
      },
      "outputs": [],
      "source": [
        "#read data\n",
        "\n",
        "covid_cumulative_cases = pd.read_csv('covid_real_data_cumulative_cases.csv', delimiter=',') #in the form of [t,S,I,D,R]\n",
        "covid_cumulative_cases.columns = ['t', 'cumulative_susceptible','cumulative_infected', 'cumulative_dead', 'cumulative_recovered'] #rename columns\n",
        "covid_cumulative_cases['t'] = covid_cumulative_cases['t'].astype(float)\n",
        "covid_cumulative_cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3EOsgFmaMfd",
        "outputId": "a32506fe-8fd1-44e4-ca94-e3debf9ac330"
      },
      "outputs": [],
      "source": [
        "#take only a sample of 31\n",
        "cumulative_susceptible = []\n",
        "cumulative_infected = [] \n",
        "cumulative_dead = []\n",
        "cumulative_recovered = []\n",
        "timesteps = []\n",
        "\n",
        "d1 = covid_cumulative_cases['cumulative_susceptible'][:310]\n",
        "d2 = covid_cumulative_cases['cumulative_infected'][:310]\n",
        "d3 = covid_cumulative_cases['cumulative_dead'][:310]\n",
        "d4 = covid_cumulative_cases['cumulative_recovered'][:310]\n",
        "d5 = covid_cumulative_cases['t'][:310]\n",
        "\n",
        "for item in range(len(d5)):\n",
        "    if item%10 == 0:\n",
        "        cumulative_susceptible.append(d1[item])\n",
        "        cumulative_infected.append(d2[item]) \n",
        "        cumulative_dead.append(d3[item])\n",
        "        cumulative_recovered.append(d4[item])\n",
        "        timesteps.append(d5[item])\n",
        "\n",
        "print(len(timesteps))        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "eXiytIPe6x2z",
        "outputId": "491e9008-3c19-476b-80a5-80642ab7bbcf"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(6,6))\n",
        "\n",
        "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
        "ax.set_facecolor('xkcd:white')\n",
        "\n",
        "# plt.plot(covid_cumulative_cases['cumulative_susceptible'][:310], label = 'cumulative Susceptible')\n",
        "# plt.plot(covid_cumulative_cases['cumulative_infected'][:310], label = 'cumulative Infected')\n",
        "# plt.plot(covid_cumulative_cases['cumulative_dead'][:310], label = 'cumulative Dead')\n",
        "# plt.plot(covid_cumulative_cases['cumulative_recovered'][:310], label = 'cumulative Recovered')\n",
        "\n",
        "plt.plot(cumulative_susceptible, label = 'cumulative Susceptible')\n",
        "# plt.plot(cumulative_infected, label = 'cumulative Infected')\n",
        "# plt.plot(cumulative_dead, label = 'cumulative Dead')\n",
        "# plt.plot(cumulative_recovered, label = 'cumulative Recovered')\n",
        "\n",
        "ax.grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
        "legend = ax.legend()\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax.spines[spine].set_visible(False)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFPz8KJlJYuL",
        "outputId": "7fcad9e7-b71b-49c1-ef3a-2acfe0eba59d"
      },
      "outputs": [],
      "source": [
        "print(timesteps[:28][-1])\n",
        "print(timesteps[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD6iFgYfZqOa",
        "outputId": "dbab277a-a162-4122-cf43-6650728d3d5d"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "PATH = 'covid_real_data_cumulative_cases' \n",
        "\n",
        "class DINN(nn.Module):\n",
        "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
        "        super(DINN, self).__init__()\n",
        "        self.N = 340e6 #population size\n",
        "        self.t = torch.tensor(t, requires_grad=True)\n",
        "        self.t_float = self.t.float()\n",
        "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
        "        self.S = torch.tensor(S_data)\n",
        "        self.I = torch.tensor(I_data)\n",
        "        self.D = torch.tensor(D_data)\n",
        "        self.R = torch.tensor(R_data)\n",
        "\n",
        "        self.losses = []\n",
        "        self.save = 3 #which file to save to\n",
        "\n",
        "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True)) #0.191\n",
        "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True)) #0.05\n",
        "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True)) #0.0294\n",
        "        \n",
        "        #find values for normalization\n",
        "        self.S_max = max(self.S)\n",
        "        self.I_max = max(self.I)\n",
        "        self.D_max = max(self.D)\n",
        "        self.R_max = max(self.R)\n",
        "        self.S_min = min(self.S)\n",
        "        self.I_min = min(self.I)\n",
        "        self.D_min = min(self.D)\n",
        "        self.R_min = min(self.R)\n",
        "\n",
        "        #unnormalize\n",
        "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
        "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
        "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
        "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)\n",
        "\n",
        "        #matrices (x4 for S,I,D,R) for the gradients\n",
        "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
        "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
        "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
        "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
        "\n",
        "        #NN\n",
        "        self.net_sidr = self.Net_sidr()\n",
        "        self.params = list(self.net_sidr.parameters())\n",
        "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
        "\n",
        "    #force parameters to be in a range\n",
        "    @property\n",
        "    def alpha(self):\n",
        "        return torch.tanh(self.alpha_tilda)*0.191*200\n",
        "\n",
        "    @property\n",
        "    def beta(self):\n",
        "        return torch.tanh(self.beta_tilda)*0.05*200\n",
        "    \n",
        "    @property\n",
        "    def gamma(self):\n",
        "        return torch.tanh(self.gamma_tilda)*0.0294*200\n",
        "\n",
        "\n",
        "    #nets\n",
        "    class Net_sidr(nn.Module): # input = [t]\n",
        "        def __init__(self):\n",
        "            super(DINN.Net_sidr, self).__init__()\n",
        "            self.fc1=nn.Linear(1, 20) \n",
        "            self.fc2=nn.Linear(20, 20)\n",
        "            self.fc3=nn.Linear(20, 20)\n",
        "            self.fc4=nn.Linear(20, 20)\n",
        "            self.fc5=nn.Linear(20, 20)\n",
        "            self.fc6=nn.Linear(20, 20)\n",
        "            self.fc7=nn.Linear(20, 20)\n",
        "            self.fc8=nn.Linear(20, 20)\n",
        "            self.out=nn.Linear(20, 4) #outputs S, I, D, R\n",
        "\n",
        "        def forward(self, t_batch):\n",
        "            sidr=F.relu(self.fc1(t_batch))\n",
        "            sidr=F.relu(self.fc2(sidr))\n",
        "            sidr=F.relu(self.fc3(sidr))\n",
        "            sidr=F.relu(self.fc4(sidr))\n",
        "            sidr=F.relu(self.fc5(sidr))\n",
        "            sidr=F.relu(self.fc6(sidr))\n",
        "            sidr=F.relu(self.fc7(sidr))\n",
        "            sidr=F.relu(self.fc8(sidr))\n",
        "            sidr=self.out(sidr)\n",
        "            return sidr\n",
        "            \n",
        "    def net_f(self, t_batch):\n",
        "        sidr_hat = self.net_sidr(t_batch)\n",
        "\n",
        "        S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
        "\n",
        "        #S_t\n",
        "        sidr_hat.backward(self.m1, retain_graph=True)\n",
        "        \n",
        "        S_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #I_t\n",
        "        sidr_hat.backward(self.m2, retain_graph=True)\n",
        "        \n",
        "        I_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #D_t\n",
        "        sidr_hat.backward(self.m3, retain_graph=True)\n",
        "        \n",
        "        D_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #R_t\n",
        "        sidr_hat.backward(self.m4, retain_graph=True)\n",
        "        \n",
        "        R_hat_t = self.t.grad.clone()\n",
        "        self.t.grad.zero_()\n",
        "\n",
        "        #unnormalize\n",
        "        S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
        "        I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
        "        D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
        "        R = self.R_min + (self.R_max - self.R_min) * R_hat\n",
        "\n",
        "        f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
        "        f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
        "        f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
        "        f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)\n",
        "\n",
        "\n",
        "        return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
        "    \n",
        "    def load(self):\n",
        "      # Load checkpoint\n",
        "      try:\n",
        "        checkpoint = torch.load(PATH + str(self.save)+'.pt') \n",
        "        print('\\nloading pre-trained model...')\n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "        epoch = checkpoint['epoch']\n",
        "         \n",
        "        self.losses = checkpoint['losses']\n",
        "         \n",
        "\n",
        "      except RuntimeError :\n",
        "          print('changed the architecture, ignore')\n",
        "          pass\n",
        "      except FileNotFoundError:\n",
        "          pass\n",
        "\n",
        "    def train(self, n_epochs):\n",
        "      #try loading\n",
        "      self.load()\n",
        "\n",
        "      #train\n",
        "      print('\\nstarting training...\\n')\n",
        "      \n",
        "      for epoch in range(n_epochs):\n",
        "        #lists to hold the output (maintain only the final epoch)\n",
        "        S_pred_list = []\n",
        "        I_pred_list = []\n",
        "        D_pred_list = []\n",
        "        R_pred_list = []\n",
        "\n",
        "         \n",
        "        f1, f2, f3, f4, S_pred, I_pred, D_pred, R_pred = self.net_f(self.t_batch)\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "        S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred) \n",
        "        I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n",
        "        D_pred_list.append(self.D_min + (self.D_max - self.D_min) * D_pred)\n",
        "        R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n",
        "\n",
        "        loss = (torch.mean(torch.square(self.S_hat[:28] - S_pred[:28]))+ \n",
        "                torch.mean(torch.square(self.I_hat[:28] - I_pred[:28]))+\n",
        "                torch.mean(torch.square(self.D_hat[:28] - D_pred[:28]))+\n",
        "                torch.mean(torch.square(self.R_hat[:28] - R_pred[:28]))+\n",
        "                torch.mean(torch.square(f1[:28]))+\n",
        "                torch.mean(torch.square(f2[:28]))+\n",
        "                torch.mean(torch.square(f3[:28]))+\n",
        "                torch.mean(torch.square(f4[:28]))\n",
        "                ) \n",
        "\n",
        "         \n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.scheduler.step() \n",
        "         \n",
        "         \n",
        "\n",
        "        self.losses.append(loss.item())\n",
        "\n",
        "        if epoch % 1000 == 0:          \n",
        "          print('\\nEpoch ', epoch)\n",
        "\n",
        "        #loss + model parameters update\n",
        "        if epoch % 4000 == 0:\n",
        "          #checkpoint save every 100 epochs if the loss is lower\n",
        "          print('\\nSaving model... Loss is: ', loss)\n",
        "          torch.save({\n",
        "              'epoch': epoch,\n",
        "              'model': self.state_dict(),\n",
        "              'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "              'scheduler': self.scheduler.state_dict(),\n",
        "              #'loss': loss,\n",
        "              'losses': self.losses,\n",
        "              }, PATH + str(self.save)+'.pt')\n",
        "          if self.save % 2 > 0: #its on 3\n",
        "            self.save = 2 #change to 2\n",
        "          else: #its on 2\n",
        "            self.save = 3 #change to 3\n",
        "\n",
        "          print('epoch: ', epoch)\n",
        "        \n",
        "\n",
        "      return S_pred_list, I_pred_list, D_pred_list, R_pred_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_P1obOwWZqOc",
        "outputId": "0dfe5a6b-905b-4db8-fdfd-130d51d1852a"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "dinn = DINN(timesteps, cumulative_susceptible, cumulative_infected, cumulative_dead, cumulative_recovered) #in the form of [t,S,I,D,R]\n",
        "\n",
        "learning_rate = 1e-5\n",
        "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
        "dinn.optimizer = optimizer\n",
        "\n",
        " \n",
        "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=1000, mode=\"exp_range\", gamma=0.85, cycle_momentum=False)\n",
        "\n",
        "dinn.scheduler = scheduler\n",
        "\n",
        "try: \n",
        "  S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(10000) #train\n",
        "except EOFError:\n",
        "  if dinn.save == 2:\n",
        "    dinn.save = 3\n",
        "    S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(10000) #train\n",
        "  elif dinn.save == 3:\n",
        "    dinn.save = 2\n",
        "    S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(10000) #train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "WwqBVtEM9FYG",
        "outputId": "77a7b291-710d-4a67-abd4-589798fefbed"
      },
      "outputs": [],
      "source": [
        "plt.plot(dinn.losses[0:], color = 'teal')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 747
        },
        "id": "cnq4p1_7cEJy",
        "outputId": "f6c88a95-ec15-46f2-8f8e-08d4d01152b6"
      },
      "outputs": [],
      "source": [
        "plt.rc('xtick', labelsize=20) \n",
        "plt.rc('ytick', labelsize=20) \n",
        "\n",
        "fig, ax = plt.subplots(2, 2, figsize = (12,12))\n",
        "\n",
        "\n",
        "ax[0, 0].set_facecolor('xkcd:white')\n",
        "ax[1, 0].set_facecolor('xkcd:white')\n",
        "ax[0, 1].set_facecolor('xkcd:white')\n",
        "ax[1, 1].set_facecolor('xkcd:white')\n",
        "\n",
        "\n",
        "ax[0, 0].scatter(timesteps[:28], cumulative_susceptible[:28], c = 'black', alpha=0.5, lw=2, label='Susceptible Data')\n",
        "ax[0, 0].scatter(timesteps[28:], cumulative_susceptible[28:], c = 'gold', alpha=0.5, lw=5, label='Future Data')\n",
        "ax[0, 0].plot(timesteps, S_pred_list[0].detach().numpy(), 'red', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
        "\n",
        "ax[1, 0].scatter(timesteps[:28], cumulative_infected[:28], c = 'violet', alpha=0.5, lw=2, label='Infected Data')\n",
        "ax[1, 0].scatter(timesteps[28:], cumulative_infected[28:], c = 'gold', alpha=0.5, lw=5, label='Future Data')\n",
        "ax[1, 0].plot(timesteps, I_pred_list[0].detach().numpy(), 'black', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
        "\n",
        "ax[0, 1].scatter(timesteps[:28], cumulative_dead[:28], c = 'black', alpha=0.5, lw=2, label='Dead Data')\n",
        "ax[0, 1].scatter(timesteps[28:], cumulative_dead[28:], c = 'gold', alpha=0.5, lw=5, label='Future Data')\n",
        "ax[0, 1].plot(timesteps, D_pred_list[0].detach().numpy(), 'green', alpha=0.9, lw=2, label='Dead Prediction', linestyle='dashed')\n",
        "\n",
        "ax[1, 1].scatter(timesteps[:28], cumulative_recovered[:28], c = 'blue', alpha=0.5, lw=2, label='Recovered Data')\n",
        "ax[1, 1].scatter(timesteps[28:], cumulative_recovered[28:], c = 'gold', alpha=0.5, lw=5, label='Future Data')\n",
        "ax[1, 1].plot(timesteps, R_pred_list[0].detach().numpy(), 'teal', alpha=0.9, lw=2, label='Recovered Prediction', linestyle='dashed')\n",
        "\n",
        "ax[0, 0].set_xlabel('Time /days',size = 20)\n",
        "ax[0, 0].set_ylabel('Number',size = 20)\n",
        "ax[0, 0].yaxis.set_tick_params(length=0)\n",
        "ax[0, 0].xaxis.set_tick_params(length=0)\n",
        "# ax[0, 0].grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
        "legend = ax[0, 0].legend(prop={'size':18})\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax[0, 0].spines[spine].set_visible(False)\n",
        "############################################################\n",
        "ax[1, 0].set_xlabel('Time /days',size = 20)\n",
        "ax[1, 0].set_ylabel('Number',size = 20)\n",
        "ax[1, 0].yaxis.set_tick_params(length=0)\n",
        "ax[1, 0].xaxis.set_tick_params(length=0)\n",
        "# ax[1, 0].grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
        "legend = ax[1, 0].legend(prop={'size':18})\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax[1, 0].spines[spine].set_visible(False)\n",
        "############################################################\n",
        "ax[0, 1].set_xlabel('Time /days',size = 20)\n",
        "ax[0, 1].set_ylabel('Number',size = 20)\n",
        "ax[0, 1].yaxis.set_tick_params(length=0)\n",
        "ax[0, 1].xaxis.set_tick_params(length=0)\n",
        "# ax[0, 1].grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
        "legend = ax[0, 1].legend(prop={'size':18})\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax[0, 1].spines[spine].set_visible(False)\n",
        "############################################################\n",
        "ax[1, 1].set_xlabel('Time /days',size = 20)\n",
        "ax[1, 1].set_ylabel('Number',size = 20)\n",
        "ax[1, 1].yaxis.set_tick_params(length=0)\n",
        "ax[1, 1].xaxis.set_tick_params(length=0)\n",
        "# ax[1, 1].grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
        "legend = ax[1,1].legend(prop={'size':18})\n",
        "legend.get_frame().set_alpha(0.5)\n",
        "for spine in ('top', 'right', 'bottom', 'left'):\n",
        "    ax[1,1].spines[spine].set_visible(False)\n",
        "############################################################\n",
        "# plt.savefig('covid_real_data_cumulative_cases.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEu_4lJML-BE",
        "outputId": "548e9c6e-eca2-4860-e1a7-787734fbed93"
      },
      "outputs": [],
      "source": [
        "print('dinn.alpha', dinn.alpha)\n",
        "print('dinn.beta', dinn.beta)\n",
        "print('dinn.gamma', dinn.gamma)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wwm2AYHTL8qS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "covid_real_data_cumulative_cases.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2"
    },
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
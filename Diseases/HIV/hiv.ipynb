{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506,"status":"ok","timestamp":1622070547390,"user":{"displayName":"Sagi Shaier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXQKL7UiRoL28-GMShElFe0PuFh4NWnMP9hbDD=s64","userId":"12455150063240177220"},"user_tz":360},"id":"pFhy95XbZqOS","outputId":"c89dcdce-f9f1-435f-f4da-1e00a4422bd6"},"outputs":[],"source":["import torch\n","from torch.autograd import grad\n","import torch.nn as nn\n","from numpy import genfromtxt\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","torch.set_printoptions(precision=6)\n","\n","hiv_data = genfromtxt('hiv.csv', delimiter=',') #in the form of [t, T, I, V]\n","\n","torch.manual_seed(1234)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":713,"status":"ok","timestamp":1622070548101,"user":{"displayName":"Sagi Shaier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXQKL7UiRoL28-GMShElFe0PuFh4NWnMP9hbDD=s64","userId":"12455150063240177220"},"user_tz":360},"id":"AD6iFgYfZqOa","outputId":"cc03d802-1ef7-4f49-e5a1-6cbc1a4997cc"},"outputs":[],"source":["%%time\n","\n","PATH = 'hiv' \n","\n","class DINN(nn.Module):\n","    def __init__(self, t, T_data, I_data, V_data): \n","        super(DINN, self).__init__()\n","        self.t = torch.tensor(t, requires_grad=True)\n","        self.t_float = self.t.float()\n","        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n","        self.T = torch.tensor(T_data) \n","        self.I = torch.tensor(I_data) \n","        self.V = torch.tensor(V_data) \n","\n","        self.losses = [] #keep the losses\n","        self.save = 2 #which file to save to\n"," \n","        #learnable parameters\n","        self.s_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.mu_T_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.mu_I_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.mu_b_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.mu_V_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.r_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.N_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.T_max_param_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.k1_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","        self.k1_prime_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n","\n","        #matrices (x3 for T,I,V) for the gradients\n","        self.m1 = torch.zeros((len(self.t), 3)); self.m1[:, 0] = 1\n","        self.m2 = torch.zeros((len(self.t), 3)); self.m2[:, 1] = 1\n","        self.m3 = torch.zeros((len(self.t), 3)); self.m3[:, 2] = 1\n","\n","        #values for norm\n","        self.T_max = max(self.T)\n","        self.I_max = max(self.I)\n","        self.V_max = max(self.V)        \n","        self.T_min = min(self.T)\n","        self.I_min = min(self.I)\n","        self.V_min = min(self.V)    \n","\n","        #normalize \n","        self.T_hat = (self.T - self.T_min) / (self.T_max - self.T_min)\n","        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n","        self.V_hat = (self.V - self.V_min) / (self.V_max - self.V_min)\n","\n","        #NN\n","        self.net_hiv = self.Net_hiv()\n","        self.params = list(self.net_hiv.parameters())\n","        self.params.extend(list([self.s_tilda, self.mu_T_tilda, self.mu_I_tilda, self.mu_b_tilda, self.mu_V_tilda, self.r_tilda, self.N_tilda, self.T_max_param_tilda, self.k1_tilda, self.k1_prime_tilda]))\n","\n","\n","    #force parameters to be in a range\n","    @property\n","    def s(self):\n","        return torch.tanh(self.s_tilda) * 0.1 + 10\n","\n","    @property\n","    def mu_T(self):\n","        return torch.tanh(self.mu_T_tilda) * 0.002 + 0.02\n","\n","    @property\n","    def mu_I(self):\n","        return torch.tanh(self.mu_I_tilda) * 0.005 + 0.26\n","\n","    @property\n","    def mu_b(self):\n","        return torch.tanh(self.mu_b_tilda) * 0.005 + 0.24\n","\n","    @property\n","    def mu_V(self):\n","        return torch.tanh(self.mu_V_tilda) * 0.1 + 2.4\n","\n","    @property\n","    def r(self):\n","        return torch.tanh(self.r_tilda) * 0.001 + 0.03 \n","\n","    @property\n","    def N(self):\n","        return torch.tanh(self.N_tilda) * 2.5 + 250\n","\n","    @property\n","    def T_max_param(self):\n","        return torch.tanh(self.T_max_param_tilda) * 15 + 1500\n","\n","    @property\n","    def k1(self):\n","        return torch.tanh(self.k1_tilda) * 1*10e-6 + 2.4*10e-5\n","\n","    @property\n","    def k1_prime(self):\n","        return torch.tanh(self.k1_prime_tilda) * 1*10e-6 + 2*10e-5\n","    \n","    #nets\n","    class Net_hiv(nn.Module): # input = [t]\n","        def __init__(self):\n","            super(DINN.Net_hiv, self).__init__()\n","            self.fc1=nn.Linear(1, 20) #takes t's\n","            self.fc2=nn.Linear(20, 20)\n","            self.fc3=nn.Linear(20, 20)\n","            self.fc4=nn.Linear(20, 20)\n","            self.fc5=nn.Linear(20, 20)\n","            self.fc6=nn.Linear(20, 20)\n","            self.fc7=nn.Linear(20, 20)\n","            self.fc8=nn.Linear(20, 20)\n","            self.out=nn.Linear(20, 3) #outputs T, I, V\n","\n","        def forward(self, t):\n","            tiv=F.relu(self.fc1(t))\n","            tiv=F.relu(self.fc2(tiv))\n","            tiv=F.relu(self.fc3(tiv))\n","            tiv=F.relu(self.fc4(tiv))\n","            tiv=F.relu(self.fc5(tiv))\n","            tiv=F.relu(self.fc6(tiv))\n","            tiv=F.relu(self.fc7(tiv))\n","            tiv=F.relu(self.fc8(tiv))\n","            tiv=self.out(tiv)\n","            return tiv    \n","\n","    def net_f(self, t_batch):       \n","        tiv_hat = self.net_hiv(t_batch)\n","\n","        T_hat, I_hat, V_hat = tiv_hat[:,0], tiv_hat[:,1], tiv_hat[:,2]\n","\n","        #T_t\n","        tiv_hat.backward(self.m1, retain_graph=True)\n","        T_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","\n","        #I_t\n","        tiv_hat.backward(self.m2, retain_graph=True)\n","        I_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","        \n","        #V_t\n","        tiv_hat.backward(self.m3, retain_graph=True)\n","        V_hat_t = self.t.grad.clone()\n","        self.t.grad.zero_()\n","        \n","        #unnormalize\n","        T = self.T_min + (self.T_max - self.T_min) * T_hat\n","        I = self.I_min + (self.I_max - self.I_min) * I_hat\n","        V = self.V_min + (self.V_max - self.V_min) * V_hat\n","\n","        f1_hat = T_hat_t - (self.s - self.mu_T * T + self.r * T * (1 - ((T + I) / self.T_max_param) - self.k1 * V * T)) / (self.T_max_param - self.T_min) \n","        f2_hat = I_hat_t - (self.k1_prime * V * T - self.mu_I * I) / (self.I_max - self.I_min)         \n","        f3_hat = V_hat_t - (self.N * self.mu_b * I - self.k1 * V * T - self.mu_V * V) / (self.V_max - self.V_min)         \n","\n","        return f1_hat, f2_hat, f3_hat, T_hat, I_hat, V_hat\n","    \n","    def load(self):\n","      # Load checkpoint\n","      try:\n","        checkpoint = torch.load(PATH + str(self.save)+'.pt') \n","        print('\\nloading pre-trained model...')\n","        self.load_state_dict(checkpoint['model'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        self.scheduler.load_state_dict(checkpoint['scheduler'])\n","        epoch = checkpoint['epoch']\n","        loss = checkpoint['loss']\n","        self.losses = checkpoint['losses']\n","        print('loaded previous loss: ', loss)\n","      except RuntimeError :\n","          print('changed the architecture, ignore')\n","          pass\n","      except FileNotFoundError:\n","          pass\n","\n","    def train(self, n_epochs):\n","      #try loading\n","      self.load()\n","\n","      #train\n","      print('\\nstarting training...\\n')\n","      \n","      for epoch in range(n_epochs):\n","        #lists to hold the output (maintain only the final epoch)\n","        T_pred_list= []\n","        I_pred_list= []\n","        V_pred_list= []\n","\n","\n","        f1, f2, f3, T_pred, I_pred, V_pred = self.net_f(self.t_batch)\n","        self.optimizer.zero_grad()\n","\n","        T_pred_list.append(self.T_min + (self.T_max - self.T_min) * T_pred) \n","        I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n","        V_pred_list.append(self.V_min + (self.V_max - self.V_min) * V_pred)\n","\n","        loss = (torch.mean(torch.square(self.T_hat - T_pred)) + torch.mean(torch.square(self.I_hat - I_pred)) + torch.mean(torch.square(self.V_hat - V_pred)) + \n","               torch.mean(torch.square(f1)) + torch.mean(torch.square(f2)) + torch.mean(torch.square(f3)))\n","\n","        loss.backward()\n","\n","        self.optimizer.step()\n","        self.scheduler.step() \n","        #self.scheduler.step(loss) \n","\n","        self.losses.append(loss.item())\n","\n","        if epoch % 1000 == 0:          \n","          print('\\nEpoch ', epoch)\n","\n","        #loss + model parameters update\n","        if epoch % 4000 == 9999:\n","          #checkpoint save\n","          print('\\nSaving model... Loss is: ', loss)\n","          torch.save({\n","              'epoch': epoch,\n","              'model': self.state_dict(),\n","              'optimizer_state_dict': self.optimizer.state_dict(),\n","              'scheduler': self.scheduler.state_dict(),\n","              'loss': loss,\n","              'losses': self.losses,\n","              }, PATH + str(self.save)+'.pt')\n","          if self.save % 2 > 0: #its on 3\n","            self.save = 2 #change to 2\n","          else: #its on 2\n","            self.save = 3 #change to 3\n","\n","          print('epoch: ', epoch)\n","          print('s: (goal 10)', self.s)\n","          print('\\nmu_T: (goal 0.02)', self.mu_T)\n","          print('\\nmu_I: (goal 0.26): ', self.mu_I)\n","          print('\\nmu_b (goal 0.24): ', self.mu_b)\n","          print('\\nmu_V: (goal 2.4): ', self.mu_V)\n","          print('\\nr (goal 0.03): ', self.r)\n","          print('\\nN (goal 250): ', self.N)\n","          print('\\nT_max (goal 1500): ', self.T_max_param)\n","          print('\\nk1 (goal 2.4*10e-5): ', self.k1)\n","          print('\\nk1_prime (goal 2*10e-5): ', self.k1_prime)\n","          print('#################################')\n","        \n","      #plot\n","      plt.plot(self.losses, color = 'teal')\n","      plt.xlabel('Epochs')\n","      plt.ylabel('Loss')\n","      return T_pred_list, I_pred_list, V_pred_list"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_P1obOwWZqOc","outputId":"93ea88d5-f80e-4947-c6a6-7861b168ef9f","tags":[]},"outputs":[],"source":["%%time\n","\n","dinn = DINN(hiv_data[0], hiv_data[1], hiv_data[2], hiv_data[3]) #t, T_data, I_data, V_data\n","\n","learning_rate = 1e-5\n","optimizer = optim.Adam(dinn.params, lr = learning_rate)\n","dinn.optimizer = optimizer\n","\n","scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-8, max_lr=1e-3, step_size_up=10000, mode=\"exp_range\", gamma=0.95, cycle_momentum=False)\n","\n","dinn.scheduler = scheduler\n","\n","try: \n","  T_pred_list, I_pred_list, V_pred_list = dinn.train(1) #train\n","except EOFError:\n","  if dinn.save == 2:\n","    dinn.save = 3\n","    T_pred_list, I_pred_list, V_pred_list = dinn.train(1) #train\n","  elif dinn.save == 3:  \n","    dinn.save = 2\n","    T_pred_list, I_pred_list, V_pred_list = dinn.train(1) #train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RY71fo4_Ic_N"},"outputs":[],"source":["plt.plot(dinn.losses[25000000:], color = 'teal')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pJrvoRWQZqOd"},"outputs":[],"source":["fig = plt.figure(figsize=(12,12))\n","\n","ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n","ax.set_facecolor('xkcd:white')\n","\n","ax.scatter(hiv_data[0], hiv_data[1], color = 'pink', alpha=0.5, lw=2, label='T Data', s=20)\n","ax.plot(hiv_data[0], T_pred_list[0].detach().numpy(), 'navy', alpha=0.9, lw=2, label='T Prediction', linestyle='dashed')\n","\n","ax.scatter(hiv_data[0], hiv_data[2], color = 'black', alpha=0.5, lw=2, label='I Data', s=20)\n","ax.plot(hiv_data[0], I_pred_list[0].detach().numpy(), 'dodgerblue', alpha=0.9, lw=2, label='I Prediction', linestyle='dashed')\n","\n","ax.scatter(hiv_data[0], hiv_data[3], color = 'darkgreen', alpha=0.5, lw=2, label='V Data', s=20)\n","ax.plot(hiv_data[0], V_pred_list[0].detach().numpy(), 'gold', alpha=0.9, lw=2, label='V Prediction', linestyle='dashed')\n","\n","\n","ax.set_xlabel('Time /days',size = 20)\n","ax.set_ylabel('Number',size = 20)\n","#ax.set_ylim([-1,50])\n","ax.yaxis.set_tick_params(length=0)\n","ax.xaxis.set_tick_params(length=0)\n","plt.xticks(size = 20)\n","plt.yticks(size = 20)\n","# ax.grid(b=True, which='major', c='black', lw=0.2, ls='-')\n","legend = ax.legend(prop={'size':20})\n","legend.get_frame().set_alpha(0.5)\n","for spine in ('top', 'right', 'bottom', 'left'):\n","    ax.spines[spine].set_visible(False)\n","plt.savefig('hiv.pdf')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iUzZI6VMZqOe"},"outputs":[],"source":["#vaccination! \n","\n","import numpy as np\n","from scipy.integrate import odeint\n","import matplotlib.pyplot as plt\n","\n","# Initial conditions\n","T0 = 1000\n","I0 = 10\n","V0 = 10e-3\n","\n","# A grid of time points (in days)\n","t = np.linspace(0, 20, 50) \n","\n","#parameters\n","s = dinn.s\n","mu_T = dinn.mu_T\n","mu_I = 0.26 #dinn.mu_I\n","mu_b = 0.24 #dinn.mu_b\n","mu_V = 2.4 #dinn.mu_V\n","r = 0.03 #dinn.r\n","N = dinn.N\n","T_max = dinn.T_max_param\n","k1 = dinn.k1\n","k1_prime = dinn.k1_prime\n","\n","print(r)\n","print(k1)\n","print(k1_prime)\n","# mu_I: (goal 0.26):  tensor([0.262541], grad_fn=<AddBackward0>)\n","\n","# mu_b (goal 0.24):  tensor([2.403510], grad_fn=<AddBackward0>)\n","\n","# mu_V: (goal 2.4):  tensor([2.400731], grad_fn=<AddBackward0>)\n","\n","# r (goal 0.03):  tensor([0.030605], grad_fn=<AddBackward0>)\n","\n","\n","\"\"\"s = 10\n","mu_T = 0.02\n","mu_I = 0.26\n","mu_b = 0.24\n","mu_V = 2.4\n","r = 0.03\n","N = 250\n","T_max = 1500\n","k1 = 2.4*10e-5\n","k1_prime = 2*10e-5\"\"\"\n","\n","# The SIR model differential equations.\n","def deriv(y, t, s, mu_T, mu_V, mu_b, r, N, T_max, k1, k1_prime):\n","    T, I, V = y\n","    dTdt = s - mu_T * T + r * T * (1 - ((T + I) / T_max) - k1 * V * T)\n","    dIdt = k1_prime * V * T - mu_I * I\n","    dVdt = N * mu_b * I - k1 * V * T - mu_V * V\n","\n","    return dTdt, dIdt, dVdt\n","\n","\n","# Initial conditions vector\n","y0 = T0, I0, V0\n","# Integrate the SIR equations over the time grid, t.\n","ret = odeint(deriv, y0, t, args=(s, mu_T, mu_V, mu_b, r, N, T_max, k1, k1_prime))\n","T, I, V = ret.T\n","\n","# Plot the data on two separate curves for S(t), I(t)\n","fig = plt.figure(figsize=(12,12))\n","\n","ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n","ax.set_facecolor('xkcd:white')\n","\n","ax.plot(t, T, 'green', alpha=0.5, lw=2, label='T_pred', linestyle='dashed')\n","ax.plot(hiv_data[0], hiv_data[1], 'teal', alpha=0.5, lw=2, label='T')\n","\n","ax.plot(t, I, 'purple', alpha=0.5, lw=2, label='I_pred', linestyle='dashed')\n","ax.plot(hiv_data[0], hiv_data[2], 'blue', alpha=0.5, lw=2, label='I')\n","\n","ax.plot(t, V, 'red', alpha=0.5, lw=2, label='V_pr', linestyle='dashed')\n","ax.plot(hiv_data[0], hiv_data[3], 'black', alpha=0.5, lw=2, label='V')\n","\n","ax.set_xlabel('Time /days')\n","ax.set_ylabel('Number')\n","ax.yaxis.set_tick_params(length=0)\n","ax.xaxis.set_tick_params(length=0)\n","ax.grid(b=True, which='major', c='black', lw=0.2, ls='-')\n","legend = ax.legend()\n","legend.get_frame().set_alpha(0.5)\n","for spine in ('top', 'right', 'bottom', 'left'):\n","    ax.spines[spine].set_visible(False)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICWNogFjn27j"},"outputs":[],"source":["#calculate relative MSE loss\n","import math\n","\n","T_total_loss = 0\n","T_den = 0\n","I_total_loss = 0\n","I_den = 0\n","V_total_loss = 0\n","V_den = 0\n","\n","for timestep in range(len(t)):\n","  T_value = hiv_data[1][timestep] - T[timestep]\n","  T_total_loss += T_value**2\n","  T_den += (hiv_data[1][timestep])**2\n","  I_value = hiv_data[2][timestep] - I[timestep]\n","  I_total_loss += I_value**2\n","  I_den += (hiv_data[2][timestep])**2\n","  V_value = hiv_data[3][timestep] - V[timestep]\n","  V_total_loss += V_value**2\n","  V_den += (hiv_data[3][timestep])**2\n","\n","T_total_loss = math.sqrt(T_total_loss/T_den)\n","I_total_loss = math.sqrt(I_total_loss/I_den)\n","V_total_loss = math.sqrt(V_total_loss/V_den)\n","\n","print('T_total_loss: ', T_total_loss)\n","print('I_total_loss: ', I_total_loss)\n","print('V_total_loss: ', V_total_loss)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"hiv.ipynb","provenance":[]},"interpreter":{"hash":"f0396a0f98e081442f6005f4438dae70905c4dba32e635697d7a979ca5a56ea2"},"kernelspec":{"display_name":"Python 3.7.3 64-bit ('base': conda)","name":"python3"},"language_info":{"name":"python","version":""}},"nbformat":4,"nbformat_minor":0}
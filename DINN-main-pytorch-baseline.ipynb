{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8494a990",
   "metadata": {
    "papermill": {
     "duration": 0.056004,
     "end_time": "2022-04-23T10:23:50.303244",
     "exception": false,
     "start_time": "2022-04-23T10:23:50.247240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DINN Tutorial --- COVID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe0284",
   "metadata": {
    "papermill": {
     "duration": 0.054408,
     "end_time": "2022-04-23T10:23:50.411740",
     "exception": false,
     "start_time": "2022-04-23T10:23:50.357332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## This notebook will show the entire process of training a neural network to learn a disease"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef9d59e",
   "metadata": {
    "papermill": {
     "duration": 0.052627,
     "end_time": "2022-04-23T10:23:50.517516",
     "exception": false,
     "start_time": "2022-04-23T10:23:50.464889",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Consider the following system of differential equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a002a5e9",
   "metadata": {
    "papermill": {
     "duration": 0.052667,
     "end_time": "2022-04-23T10:23:50.623571",
     "exception": false,
     "start_time": "2022-04-23T10:23:50.570904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "dS/dt = - (alpha / N)  S  I\n",
    "\n",
    "dI/dt = (alpha / N)  S  I - beta  I - gamma  I \n",
    "\n",
    "dD/dt = gamma  I\n",
    "\n",
    "dR/dt = beta  I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd64bce0",
   "metadata": {
    "papermill": {
     "duration": 0.052759,
     "end_time": "2022-04-23T10:23:50.729335",
     "exception": false,
     "start_time": "2022-04-23T10:23:50.676576",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Where \n",
    "\n",
    "beta = “effective/apparent” per day recovery rates\n",
    "\n",
    "gamma = “effective/apparent” per day fatality rates\n",
    "\n",
    "alpha = infection rate\n",
    "\n",
    "N = population size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a179b9",
   "metadata": {
    "papermill": {
     "duration": 0.05281,
     "end_time": "2022-04-23T10:23:50.834942",
     "exception": false,
     "start_time": "2022-04-23T10:23:50.782132",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## This system represents a COVID model and has 4 compartments: susceptible, infected, dead, and recovered\n",
    "\n",
    "## Since we don't have actual data from the environment to work with, we will generate it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971ecdd9",
   "metadata": {
    "papermill": {
     "duration": 0.069133,
     "end_time": "2022-04-23T10:23:50.959121",
     "exception": false,
     "start_time": "2022-04-23T10:23:50.889988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import libraries for generating & visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31bea3df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:51.071855Z",
     "iopub.status.busy": "2022-04-23T10:23:51.070682Z",
     "iopub.status.idle": "2022-04-23T10:23:51.699630Z",
     "shell.execute_reply": "2022-04-23T10:23:51.698858Z"
    },
    "papermill": {
     "duration": 0.685611,
     "end_time": "2022-04-23T10:23:51.699790",
     "exception": false,
     "start_time": "2022-04-23T10:23:51.014179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import odeint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86b369",
   "metadata": {
    "papermill": {
     "duration": 0.055262,
     "end_time": "2022-04-23T10:23:51.808705",
     "exception": false,
     "start_time": "2022-04-23T10:23:51.753443",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We start by setting some information that we got from the literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64600849",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:51.925627Z",
     "iopub.status.busy": "2022-04-23T10:23:51.921948Z",
     "iopub.status.idle": "2022-04-23T10:23:51.927471Z",
     "shell.execute_reply": "2022-04-23T10:23:51.927933Z"
    },
    "papermill": {
     "duration": 0.062839,
     "end_time": "2022-04-23T10:23:51.928097",
     "exception": false,
     "start_time": "2022-04-23T10:23:51.865258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial conditions (from the literature)\n",
    "N = 59e6 #population size\n",
    "\n",
    "S0 = N - 1 #everyone starts out as susceptible, except for 1 person that is infected\n",
    "I0 = 1 #1 infected person\n",
    "D0 = 0\n",
    "R0 = 0\n",
    "\n",
    "# A grid of time points (in days)\n",
    "t = np.linspace(0, 500, 100) #from day 0 to day 500, generate 100 points\n",
    "\n",
    "#parameters (from the literature)\n",
    "alpha = 0.191\n",
    "beta = 0.05\n",
    "gamma = 0.0294"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade9c7ed",
   "metadata": {
    "papermill": {
     "duration": 0.054605,
     "end_time": "2022-04-23T10:23:52.038047",
     "exception": false,
     "start_time": "2022-04-23T10:23:51.983442",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We then write out the system of equations in a function that will calculate the value of each compartment at each time step (e.g day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee362d5b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:52.160503Z",
     "iopub.status.busy": "2022-04-23T10:23:52.159482Z",
     "iopub.status.idle": "2022-04-23T10:23:52.162230Z",
     "shell.execute_reply": "2022-04-23T10:23:52.163031Z"
    },
    "papermill": {
     "duration": 0.071464,
     "end_time": "2022-04-23T10:23:52.163259",
     "exception": false,
     "start_time": "2022-04-23T10:23:52.091795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The SIR model differential equations.\n",
    "def deriv(y, t, alpha, betta, gamma):\n",
    "    S, I, D, R = y\n",
    "    dSdt = - (alpha / N) * S * I\n",
    "    dIdt = (alpha / N) * S * I - beta * I - gamma * I \n",
    "    dDdt = gamma * I\n",
    "    dRdt = beta * I\n",
    "\n",
    "    return dSdt, dIdt, dDdt, dRdt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366e754a",
   "metadata": {
    "papermill": {
     "duration": 0.05661,
     "end_time": "2022-04-23T10:23:52.291128",
     "exception": false,
     "start_time": "2022-04-23T10:23:52.234518",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## And then we pass the initial conditions to the function to get the values of each compartment for the length we chose before (500 days, 100 data points per compartment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2d023ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:52.416842Z",
     "iopub.status.busy": "2022-04-23T10:23:52.416153Z",
     "iopub.status.idle": "2022-04-23T10:23:52.427122Z",
     "shell.execute_reply": "2022-04-23T10:23:52.427687Z"
    },
    "papermill": {
     "duration": 0.069027,
     "end_time": "2022-04-23T10:23:52.427865",
     "exception": false,
     "start_time": "2022-04-23T10:23:52.358838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initial conditions vector\n",
    "y0 = S0, I0, D0, R0\n",
    "# Integrate the SIR equations over the time grid, t.\n",
    "ret = odeint(deriv, y0, t, args=(alpha, beta, gamma))\n",
    "S, I, D, R = ret.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4d3004",
   "metadata": {
    "papermill": {
     "duration": 0.056486,
     "end_time": "2022-04-23T10:23:52.556675",
     "exception": false,
     "start_time": "2022-04-23T10:23:52.500189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## We can now plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb04bbde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:52.674206Z",
     "iopub.status.busy": "2022-04-23T10:23:52.673440Z",
     "iopub.status.idle": "2022-04-23T10:23:52.987542Z",
     "shell.execute_reply": "2022-04-23T10:23:52.988212Z"
    },
    "papermill": {
     "duration": 0.375356,
     "end_time": "2022-04-23T10:23:52.988389",
     "exception": false,
     "start_time": "2022-04-23T10:23:52.613033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the data\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "ax.plot(t, S, 'violet', alpha=0.5, lw=2, label='Susceptible', linestyle='dashed')\n",
    "ax.plot(t, I, 'darkgreen', alpha=0.5, lw=2, label='Infected', linestyle='dashed')\n",
    "ax.plot(t, D, 'blue', alpha=0.5, lw=2, label='Dead', linestyle='dashed')\n",
    "ax.plot(t, R, 'red', alpha=0.5, lw=2, label='Recovered', linestyle='dashed')\n",
    "\n",
    "ax.set_xlabel('Time /days')\n",
    "ax.set_ylabel('Number')\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "ax.grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
    "legend = ax.legend()\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "for spine in ('top', 'right', 'bottom', 'left'):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53279bd6",
   "metadata": {
    "papermill": {
     "duration": 0.056113,
     "end_time": "2022-04-23T10:23:53.106384",
     "exception": false,
     "start_time": "2022-04-23T10:23:53.050271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## And to save the results as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af032b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:53.224893Z",
     "iopub.status.busy": "2022-04-23T10:23:53.224214Z",
     "iopub.status.idle": "2022-04-23T10:23:53.227531Z",
     "shell.execute_reply": "2022-04-23T10:23:53.228146Z"
    },
    "papermill": {
     "duration": 0.065465,
     "end_time": "2022-04-23T10:23:53.228312",
     "exception": false,
     "start_time": "2022-04-23T10:23:53.162847",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#save to csv file\n",
    "COVID_Data = np.asarray([t, S, I, D, R]) \n",
    "\n",
    "np.savetxt(\"COVID_Tutorial.csv\", COVID_Data, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92668735",
   "metadata": {
    "papermill": {
     "duration": 0.060693,
     "end_time": "2022-04-23T10:23:53.349278",
     "exception": false,
     "start_time": "2022-04-23T10:23:53.288585",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Great! Now we have data to work with. On to training a neural network.\n",
    "I will break down the entire training process into parts. These parts might NOT be runnable on their own (meaning, you can't run the code -- which is why I will comment them out). The point is, I think that it will be easier to understand the process by first understanding what each part is doing, and then seeing how they all work together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6a1b97",
   "metadata": {
    "papermill": {
     "duration": 0.05713,
     "end_time": "2022-04-23T10:23:53.466524",
     "exception": false,
     "start_time": "2022-04-23T10:23:53.409394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28bce32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:53.584124Z",
     "iopub.status.busy": "2022-04-23T10:23:53.583112Z",
     "iopub.status.idle": "2022-04-23T10:23:54.727630Z",
     "shell.execute_reply": "2022-04-23T10:23:54.728190Z"
    },
    "papermill": {
     "duration": 1.204262,
     "end_time": "2022-04-23T10:23:54.728383",
     "exception": false,
     "start_time": "2022-04-23T10:23:53.524121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fea39968850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import grad\n",
    "import torch.nn as nn\n",
    "from numpy import genfromtxt\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1234) #set seed (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d149ee",
   "metadata": {
    "papermill": {
     "duration": 0.059751,
     "end_time": "2022-04-23T10:23:54.848766",
     "exception": false,
     "start_time": "2022-04-23T10:23:54.789015",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b54deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:54.973435Z",
     "iopub.status.busy": "2022-04-23T10:23:54.972735Z",
     "iopub.status.idle": "2022-04-23T10:23:54.978941Z",
     "shell.execute_reply": "2022-04-23T10:23:54.979384Z"
    },
    "papermill": {
     "duration": 0.068733,
     "end_time": "2022-04-23T10:23:54.979561",
     "exception": false,
     "start_time": "2022-04-23T10:23:54.910828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "covid_data = genfromtxt('COVID_Tutorial.csv', delimiter=',') #in the form of [t,S,I,D,R]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da2ac1b",
   "metadata": {
    "papermill": {
     "duration": 0.058187,
     "end_time": "2022-04-23T10:23:55.095372",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.037185",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Define the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29c2fe7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:55.223308Z",
     "iopub.status.busy": "2022-04-23T10:23:55.222295Z",
     "iopub.status.idle": "2022-04-23T10:23:55.226901Z",
     "shell.execute_reply": "2022-04-23T10:23:55.227437Z"
    },
    "papermill": {
     "duration": 0.071041,
     "end_time": "2022-04-23T10:23:55.227593",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.156552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): # remember that the data was saved as [t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        # here all the \"loading the data\" and training is happening\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da491c2",
   "metadata": {
    "papermill": {
     "duration": 0.058017,
     "end_time": "2022-04-23T10:23:55.344813",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.286796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Now we need to define some initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f149786",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:55.462285Z",
     "iopub.status.busy": "2022-04-23T10:23:55.461357Z",
     "iopub.status.idle": "2022-04-23T10:23:55.468679Z",
     "shell.execute_reply": "2022-04-23T10:23:55.469225Z"
    },
    "papermill": {
     "duration": 0.067736,
     "end_time": "2022-04-23T10:23:55.469384",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.401648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50c21c",
   "metadata": {
    "papermill": {
     "duration": 0.058252,
     "end_time": "2022-04-23T10:23:55.585056",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.526804",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. There are two options for this part. Either you know the values of the parameters (alpha, beta, gamma) or you don't. \n",
    "If you're wondering how can we not know their values if we just generated the data using them, remember that we can also get the data from the environment, and so we might not have the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0917f",
   "metadata": {
    "papermill": {
     "duration": 0.058027,
     "end_time": "2022-04-23T10:23:55.700056",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.642029",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## If we don't know their values, we let the neural network learn it\n",
    "Note that the reason for the \"tilda\" part will be clear soon. It's basically to bound the variables around a certain range (imagine telling the neural network to learn alpha, but not from negative infinity to infinity, but from -100 to 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ff20a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:55.825704Z",
     "iopub.status.busy": "2022-04-23T10:23:55.824729Z",
     "iopub.status.idle": "2022-04-23T10:23:55.827947Z",
     "shell.execute_reply": "2022-04-23T10:23:55.828436Z"
    },
    "papermill": {
     "duration": 0.067867,
     "end_time": "2022-04-23T10:23:55.828596",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.760729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "# self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "# self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab3646",
   "metadata": {
    "papermill": {
     "duration": 0.060096,
     "end_time": "2022-04-23T10:23:55.946851",
     "exception": false,
     "start_time": "2022-04-23T10:23:55.886755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## If we do know their values, we just set it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47b16f11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:56.070815Z",
     "iopub.status.busy": "2022-04-23T10:23:56.069855Z",
     "iopub.status.idle": "2022-04-23T10:23:56.073046Z",
     "shell.execute_reply": "2022-04-23T10:23:56.073481Z"
    },
    "papermill": {
     "duration": 0.066352,
     "end_time": "2022-04-23T10:23:56.073659",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.007307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# self.alpha_tilda = torch.tensor(0.191)\n",
    "# self.beta_tilda = torch.tensor(0.05)\n",
    "# self.gamma_tilda = torch.tensor(0.0294)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d156d9",
   "metadata": {
    "papermill": {
     "duration": 0.057216,
     "end_time": "2022-04-23T10:23:56.188453",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.131237",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Let's assume we don't know them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f13413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:56.308470Z",
     "iopub.status.busy": "2022-04-23T10:23:56.307485Z",
     "iopub.status.idle": "2022-04-23T10:23:56.316436Z",
     "shell.execute_reply": "2022-04-23T10:23:56.316902Z"
    },
    "papermill": {
     "duration": 0.071406,
     "end_time": "2022-04-23T10:23:56.317069",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.245663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97bbc66",
   "metadata": {
    "papermill": {
     "duration": 0.057396,
     "end_time": "2022-04-23T10:23:56.432350",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.374954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Normalize the data\n",
    "Remember that our population size was 59 mil? Remember that there was only 1 infected person and almost 59 mil susceptible people? These drastic variations in values are quite challenging for the network to learn. So we normalize each compartment to be between 0 and 1 for the sake of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "780f3d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:56.552633Z",
     "iopub.status.busy": "2022-04-23T10:23:56.552029Z",
     "iopub.status.idle": "2022-04-23T10:23:56.554123Z",
     "shell.execute_reply": "2022-04-23T10:23:56.553519Z"
    },
    "papermill": {
     "duration": 0.064332,
     "end_time": "2022-04-23T10:23:56.554257",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.489925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# find values for normalization\n",
    "\n",
    "# max values\n",
    "# self.S_max = max(self.S)\n",
    "# self.I_max = max(self.I)\n",
    "# self.D_max = max(self.D)\n",
    "# self.R_max = max(self.R)\n",
    "\n",
    "# min values\n",
    "# self.S_min = min(self.S)\n",
    "# self.I_min = min(self.I)\n",
    "# self.D_min = min(self.D)\n",
    "# self.R_min = min(self.R)\n",
    "\n",
    "# create new normalized parameters (which is why the \"hat\" parts)\n",
    "# self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "# self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "# self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "# self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7224fc8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:56.672091Z",
     "iopub.status.busy": "2022-04-23T10:23:56.671458Z",
     "iopub.status.idle": "2022-04-23T10:23:56.684238Z",
     "shell.execute_reply": "2022-04-23T10:23:56.684724Z"
    },
    "papermill": {
     "duration": 0.073294,
     "end_time": "2022-04-23T10:23:56.684903",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.611609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ca75f",
   "metadata": {
    "papermill": {
     "duration": 0.05767,
     "end_time": "2022-04-23T10:23:56.800265",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.742595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. A bit \"hacky\" way to calculate the gradients later\n",
    "It doesn't seem like PyTorch has an easy way to calculate gradients. The issue is that \"grad\" only knows how to propagate gradients from a scalar tensor (which our network's output is not), which is why I had to calculate the Jacobian.\n",
    "So instead of calculating the entire jacobian, I'm using this \"hacky\" way\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9dd8cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:56.918638Z",
     "iopub.status.busy": "2022-04-23T10:23:56.918038Z",
     "iopub.status.idle": "2022-04-23T10:23:56.921394Z",
     "shell.execute_reply": "2022-04-23T10:23:56.921955Z"
    },
    "papermill": {
     "duration": 0.064318,
     "end_time": "2022-04-23T10:23:56.922124",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.857806",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# matrices (x4 for S,I,D,R) for the gradients\n",
    "# What's important here:\n",
    "# We have 4 compartments, hence the value 4 in \"torch.zeros((len(self.t), 4))\". \n",
    "# If we had 20 compartments we would write torch.zeros((len(self.t), 20))\n",
    "# Also, we're setting each specific column in the formed matrices to 1\n",
    "\n",
    "# self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "# self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "# self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "# self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "# See (https://stackoverflow.com/questions/67472361/using-pytorchs-autograd-efficiently-with-tensors-by-calculating-the-jacobian) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23d029ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:57.041567Z",
     "iopub.status.busy": "2022-04-23T10:23:57.040934Z",
     "iopub.status.idle": "2022-04-23T10:23:57.056512Z",
     "shell.execute_reply": "2022-04-23T10:23:57.057051Z"
    },
    "papermill": {
     "duration": 0.077263,
     "end_time": "2022-04-23T10:23:57.057218",
     "exception": false,
     "start_time": "2022-04-23T10:23:56.979955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb59a7c",
   "metadata": {
    "papermill": {
     "duration": 0.058053,
     "end_time": "2022-04-23T10:23:57.173274",
     "exception": false,
     "start_time": "2022-04-23T10:23:57.115221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 8. Let's initialize the network and learnable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bc76bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:57.294342Z",
     "iopub.status.busy": "2022-04-23T10:23:57.293673Z",
     "iopub.status.idle": "2022-04-23T10:23:57.295313Z",
     "shell.execute_reply": "2022-04-23T10:23:57.295786Z"
    },
    "papermill": {
     "duration": 0.064558,
     "end_time": "2022-04-23T10:23:57.295961",
     "exception": false,
     "start_time": "2022-04-23T10:23:57.231403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Initializing the neural network\n",
    "# self.net_sidr = self.Net_sidr()\n",
    "\n",
    "# # adding the parameters (alpha, beta, gamma) to the list of learnable parameters (basically, without this part only the neural network's weights will be updated, so we're telling the model to learn alpha, beta, and gamma as well)\n",
    "# self.params = list(self.net_sidr.parameters())\n",
    "# self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0acfbe3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:57.417367Z",
     "iopub.status.busy": "2022-04-23T10:23:57.416644Z",
     "iopub.status.idle": "2022-04-23T10:23:57.433676Z",
     "shell.execute_reply": "2022-04-23T10:23:57.434163Z"
    },
    "papermill": {
     "duration": 0.079264,
     "end_time": "2022-04-23T10:23:57.434338",
     "exception": false,
     "start_time": "2022-04-23T10:23:57.355074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0b365",
   "metadata": {
    "papermill": {
     "duration": 0.058412,
     "end_time": "2022-04-23T10:23:57.551550",
     "exception": false,
     "start_time": "2022-04-23T10:23:57.493138",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 9. Forcing the parameters to be in a certain range\n",
    "As I mentioned before, we could let the model learn the parameters from negative infinity to infinity, but why should we? These parameters usually have some plausible range. Here we force these ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5e04bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:57.672716Z",
     "iopub.status.busy": "2022-04-23T10:23:57.671675Z",
     "iopub.status.idle": "2022-04-23T10:23:57.680133Z",
     "shell.execute_reply": "2022-04-23T10:23:57.680680Z"
    },
    "papermill": {
     "duration": 0.0706,
     "end_time": "2022-04-23T10:23:57.680846",
     "exception": false,
     "start_time": "2022-04-23T10:23:57.610246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#force parameters to be in the range of (-1, 1)\n",
    "@property\n",
    "def alpha(self):\n",
    "    return torch.tanh(self.alpha_tilda) \n",
    "\n",
    "@property\n",
    "def beta(self):\n",
    "    return torch.tanh(self.beta_tilda) \n",
    "\n",
    "@property\n",
    "def gamma(self):\n",
    "    return torch.tanh(self.gamma_tilda) \n",
    "\n",
    "\n",
    "#note that you can easily play with that:\n",
    "\n",
    "#force parameters to be in various ranges\n",
    "@property\n",
    "def alpha(self):\n",
    "    return torch.tanh(self.alpha_tilda) * 0.5 # range of (-0.5, 0.5)\n",
    "\n",
    "@property\n",
    "def beta(self):\n",
    "    return torch.tanh(self.beta_tilda) * 0.01 + 1 # range of (-0.99, 1.01)\n",
    "\n",
    "@property\n",
    "def gamma(self):\n",
    "    return torch.tanh(self.gamma_tilda) * 100 # range of (-100, 100)\n",
    "\n",
    "\n",
    "# Also note that we call these alpha, beta, and gamma (in comparison to \"alpha_tilda\", etc. from before)\n",
    "\n",
    "# If you know the values of the parameters you just need to change this to:\n",
    "@property\n",
    "def alpha(self):\n",
    "    return self.alpha_tilda\n",
    "\n",
    "@property\n",
    "def beta(self):\n",
    "    return self.beta_tilda\n",
    "\n",
    "@property\n",
    "def gamma(self):\n",
    "    return self.gamma_tilda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "306b821e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:57.802239Z",
     "iopub.status.busy": "2022-04-23T10:23:57.801221Z",
     "iopub.status.idle": "2022-04-23T10:23:57.820085Z",
     "shell.execute_reply": "2022-04-23T10:23:57.820596Z"
    },
    "papermill": {
     "duration": 0.081173,
     "end_time": "2022-04-23T10:23:57.820761",
     "exception": false,
     "start_time": "2022-04-23T10:23:57.739588",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) \n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) \n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30d4f31",
   "metadata": {
    "papermill": {
     "duration": 0.058686,
     "end_time": "2022-04-23T10:23:57.940337",
     "exception": false,
     "start_time": "2022-04-23T10:23:57.881651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 10. Creating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff8eaefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:58.063609Z",
     "iopub.status.busy": "2022-04-23T10:23:58.062641Z",
     "iopub.status.idle": "2022-04-23T10:23:58.072755Z",
     "shell.execute_reply": "2022-04-23T10:23:58.073450Z"
    },
    "papermill": {
     "duration": 0.073589,
     "end_time": "2022-04-23T10:23:58.073635",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.000046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "    def __init__(self):\n",
    "        super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "        self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "        self.fc2=nn.Linear(20, 20)\n",
    "        self.fc3=nn.Linear(20, 20)\n",
    "        self.fc4=nn.Linear(20, 20)\n",
    "        self.fc5=nn.Linear(20, 20)\n",
    "        self.fc6=nn.Linear(20, 20)\n",
    "        self.fc7=nn.Linear(20, 20)\n",
    "        self.fc8=nn.Linear(20, 20)\n",
    "        self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "    def forward(self, t_batch):\n",
    "        sidr=F.relu(self.fc1(t_batch))\n",
    "        sidr=F.relu(self.fc2(sidr))\n",
    "        sidr=F.relu(self.fc3(sidr))\n",
    "        sidr=F.relu(self.fc4(sidr))\n",
    "        sidr=F.relu(self.fc5(sidr))\n",
    "        sidr=F.relu(self.fc6(sidr))\n",
    "        sidr=F.relu(self.fc7(sidr))\n",
    "        sidr=F.relu(self.fc8(sidr))\n",
    "        sidr=self.out(sidr)\n",
    "        return sidr\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bf92198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:58.196950Z",
     "iopub.status.busy": "2022-04-23T10:23:58.195951Z",
     "iopub.status.idle": "2022-04-23T10:23:58.221934Z",
     "shell.execute_reply": "2022-04-23T10:23:58.222471Z"
    },
    "papermill": {
     "duration": 0.08954,
     "end_time": "2022-04-23T10:23:58.222639",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.133099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f593081",
   "metadata": {
    "papermill": {
     "duration": 0.059366,
     "end_time": "2022-04-23T10:23:58.341292",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.281926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 11. Now the somewhat complicated part, we create another function that takes the timesteps batch, and pass it to the neural network \n",
    "We basically want to optimize the neural network and also this function that has the system of equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1268b8b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:58.464759Z",
     "iopub.status.busy": "2022-04-23T10:23:58.463817Z",
     "iopub.status.idle": "2022-04-23T10:23:58.468528Z",
     "shell.execute_reply": "2022-04-23T10:23:58.469143Z"
    },
    "papermill": {
     "duration": 0.068139,
     "end_time": "2022-04-23T10:23:58.469307",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.401168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def net_f(self, t_batch):\n",
    "        \n",
    "        #pass the timesteps batch to the neural network\n",
    "        sidr_hat = self.net_sidr(t_batch)\n",
    "        \n",
    "        #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "        S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdeda796",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:58.607944Z",
     "iopub.status.busy": "2022-04-23T10:23:58.591578Z",
     "iopub.status.idle": "2022-04-23T10:23:58.618810Z",
     "shell.execute_reply": "2022-04-23T10:23:58.619434Z"
    },
    "papermill": {
     "duration": 0.090972,
     "end_time": "2022-04-23T10:23:58.619609",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.528637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68430b8b",
   "metadata": {
    "papermill": {
     "duration": 0.059254,
     "end_time": "2022-04-23T10:23:58.738926",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.679672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 12. we now want to get the derivative of each compartment with respect to time (this is why we had to do the \"hacky\" jacobian part)\n",
    "We do this to plug in the systems of equations (you'll see in the next step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1130efdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:58.864813Z",
     "iopub.status.busy": "2022-04-23T10:23:58.864172Z",
     "iopub.status.idle": "2022-04-23T10:23:58.868157Z",
     "shell.execute_reply": "2022-04-23T10:23:58.868708Z"
    },
    "papermill": {
     "duration": 0.069544,
     "end_time": "2022-04-23T10:23:58.868911",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.799367",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #S_t\n",
    "# sidr_hat.backward(self.m1, retain_graph=True)\n",
    "# S_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()\n",
    "\n",
    "# #I_t\n",
    "# sidr_hat.backward(self.m2, retain_graph=True)\n",
    "# I_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()\n",
    "\n",
    "# #D_t\n",
    "# sidr_hat.backward(self.m3, retain_graph=True)\n",
    "# D_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()\n",
    "\n",
    "# #R_t\n",
    "# sidr_hat.backward(self.m4, retain_graph=True)\n",
    "# R_hat_t = self.t.grad.clone()\n",
    "# self.t.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96f301c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:58.996825Z",
     "iopub.status.busy": "2022-04-23T10:23:58.995675Z",
     "iopub.status.idle": "2022-04-23T10:23:59.026376Z",
     "shell.execute_reply": "2022-04-23T10:23:59.026923Z"
    },
    "papermill": {
     "duration": 0.09651,
     "end_time": "2022-04-23T10:23:59.027094",
     "exception": false,
     "start_time": "2022-04-23T10:23:58.930584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e35333",
   "metadata": {
    "papermill": {
     "duration": 0.059593,
     "end_time": "2022-04-23T10:23:59.147145",
     "exception": false,
     "start_time": "2022-04-23T10:23:59.087552",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 13. We now unnormalize the compartments because we don't actually want the equations to change, we just wanted the network to learn quicker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17a48199",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:59.270690Z",
     "iopub.status.busy": "2022-04-23T10:23:59.269685Z",
     "iopub.status.idle": "2022-04-23T10:23:59.273088Z",
     "shell.execute_reply": "2022-04-23T10:23:59.273667Z"
    },
    "papermill": {
     "duration": 0.066812,
     "end_time": "2022-04-23T10:23:59.273829",
     "exception": false,
     "start_time": "2022-04-23T10:23:59.207017",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #unnormalize\n",
    "# S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "# I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "# D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "# R = self.R_min + (self.R_max - self.R_min) * R_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e4676b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:59.397914Z",
     "iopub.status.busy": "2022-04-23T10:23:59.396847Z",
     "iopub.status.idle": "2022-04-23T10:23:59.428861Z",
     "shell.execute_reply": "2022-04-23T10:23:59.429420Z"
    },
    "papermill": {
     "duration": 0.096006,
     "end_time": "2022-04-23T10:23:59.429589",
     "exception": false,
     "start_time": "2022-04-23T10:23:59.333583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f10a78",
   "metadata": {
    "papermill": {
     "duration": 0.059754,
     "end_time": "2022-04-23T10:23:59.549340",
     "exception": false,
     "start_time": "2022-04-23T10:23:59.489586",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 14. Lastly (almost), we write out the systems of equations we want to learn\n",
    "These are almost the same as the initial system of equations, except that we have another normalization component here (e.g \"/ (self.S_max - self.S_min)\"), and also that we use the partial derivates (e.g \"S\" with respect to time) here. We basically moved the right side of each compartment to the left (hence the negative signs after the derivatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a11ec57f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:59.673719Z",
     "iopub.status.busy": "2022-04-23T10:23:59.672749Z",
     "iopub.status.idle": "2022-04-23T10:23:59.676286Z",
     "shell.execute_reply": "2022-04-23T10:23:59.676848Z"
    },
    "papermill": {
     "duration": 0.067556,
     "end_time": "2022-04-23T10:23:59.677036",
     "exception": false,
     "start_time": "2022-04-23T10:23:59.609480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "# f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "# f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "# f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e0de255e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:23:59.802017Z",
     "iopub.status.busy": "2022-04-23T10:23:59.800951Z",
     "iopub.status.idle": "2022-04-23T10:23:59.835822Z",
     "shell.execute_reply": "2022-04-23T10:23:59.836412Z"
    },
    "papermill": {
     "duration": 0.099191,
     "end_time": "2022-04-23T10:23:59.836595",
     "exception": false,
     "start_time": "2022-04-23T10:23:59.737404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        \n",
    "\n",
    "            f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "            f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "            f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "            f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53524138",
   "metadata": {
    "papermill": {
     "duration": 0.060601,
     "end_time": "2022-04-23T10:23:59.958257",
     "exception": false,
     "start_time": "2022-04-23T10:23:59.897656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 15. Lastly, we return the values we learned and want to optimize --- S, I, D, R, and each system's compartment (e.g f1_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e6bd969",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:24:00.083807Z",
     "iopub.status.busy": "2022-04-23T10:24:00.082820Z",
     "iopub.status.idle": "2022-04-23T10:24:00.086280Z",
     "shell.execute_reply": "2022-04-23T10:24:00.086829Z"
    },
    "papermill": {
     "duration": 0.067973,
     "end_time": "2022-04-23T10:24:00.087009",
     "exception": false,
     "start_time": "2022-04-23T10:24:00.019036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a824d2a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:24:00.212716Z",
     "iopub.status.busy": "2022-04-23T10:24:00.211688Z",
     "iopub.status.idle": "2022-04-23T10:24:00.246944Z",
     "shell.execute_reply": "2022-04-23T10:24:00.247456Z"
    },
    "papermill": {
     "duration": 0.099595,
     "end_time": "2022-04-23T10:24:00.247634",
     "exception": false,
     "start_time": "2022-04-23T10:24:00.148039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        \n",
    "\n",
    "            f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "            f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "            f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "            f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)        \n",
    "\n",
    "            return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfac617",
   "metadata": {
    "papermill": {
     "duration": 0.061408,
     "end_time": "2022-04-23T10:24:00.369976",
     "exception": false,
     "start_time": "2022-04-23T10:24:00.308568",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 15. The training process:\n",
    "Here we just create a function called \"train\", that will take a number of epochs to train for, and will train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "538db1aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:24:00.495624Z",
     "iopub.status.busy": "2022-04-23T10:24:00.494665Z",
     "iopub.status.idle": "2022-04-23T10:24:00.507065Z",
     "shell.execute_reply": "2022-04-23T10:24:00.507613Z"
    },
    "papermill": {
     "duration": 0.076826,
     "end_time": "2022-04-23T10:24:00.507769",
     "exception": false,
     "start_time": "2022-04-23T10:24:00.430943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(self, n_epochs):\n",
    "      # train\n",
    "      print('\\nstarting training...\\n')\n",
    "      \n",
    "      for epoch in range(n_epochs):\n",
    "        # lists to hold the output (maintain only the final epoch)\n",
    "        S_pred_list = []\n",
    "        I_pred_list = []\n",
    "        D_pred_list = []\n",
    "        R_pred_list = []\n",
    "\n",
    "        # we pass the timesteps batch into net_f\n",
    "        f1, f2, f3, f4, S_pred, I_pred, D_pred, R_pred = self.net_f(self.t_batch) # net_f outputs f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
    "        \n",
    "        self.optimizer.zero_grad() #zero grad\n",
    "        \n",
    "        #append the values to plot later (note that we unnormalize them here for plotting)\n",
    "        S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred)\n",
    "        I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n",
    "        D_pred_list.append(self.D_min + (self.D_max - self.D_min) * D_pred)\n",
    "        R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n",
    "\n",
    "        #calculate the loss --- MSE of the neural networks output and each compartment\n",
    "        loss = (torch.mean(torch.square(self.S_hat - S_pred))+ \n",
    "                torch.mean(torch.square(self.I_hat - I_pred))+\n",
    "                torch.mean(torch.square(self.D_hat - D_pred))+\n",
    "                torch.mean(torch.square(self.R_hat - R_pred))+\n",
    "                torch.mean(torch.square(f1))+\n",
    "                torch.mean(torch.square(f2))+\n",
    "                torch.mean(torch.square(f3))+\n",
    "                torch.mean(torch.square(f4))\n",
    "                ) \n",
    "\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.scheduler.step() \n",
    "\n",
    "        # append the loss value (we call \"loss.item()\" because we just want the value of the loss and not the entire computational graph)\n",
    "        self.losses.append(loss.item())\n",
    "\n",
    "        if epoch % 1000 == 0:          \n",
    "          print('\\nEpoch ', epoch)\n",
    "\n",
    "          print('alpha: (goal 0.191 ', self.alpha)\n",
    "          print('beta: (goal 0.05 ', self.beta)\n",
    "          print('gamma: (goal 0.0294 ', self.gamma)\n",
    "\n",
    "          print('#################################')                \n",
    "\n",
    "      return S_pred_list, I_pred_list, D_pred_list, R_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a552e00b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:24:00.634743Z",
     "iopub.status.busy": "2022-04-23T10:24:00.633658Z",
     "iopub.status.idle": "2022-04-23T10:24:00.676930Z",
     "shell.execute_reply": "2022-04-23T10:24:00.677452Z"
    },
    "papermill": {
     "duration": 0.108577,
     "end_time": "2022-04-23T10:24:00.677629",
     "exception": false,
     "start_time": "2022-04-23T10:24:00.569052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DINN(nn.Module):\n",
    "    def __init__(self, t, S_data, I_data, D_data, R_data): #[t,S,I,D,R]\n",
    "        super(DINN, self).__init__()\n",
    "        \n",
    "        self.N = 59e6 #population size\n",
    "        \n",
    "        #for the time steps, we need to convert them to a tensor, a float, and eventually to reshape it so it can be used as a batch\n",
    "        self.t = torch.tensor(t, requires_grad=True)\n",
    "        self.t_float = self.t.float()\n",
    "        self.t_batch = torch.reshape(self.t_float, (len(self.t),1)) #reshape for batch \n",
    "\n",
    "        #for the compartments we just need to convert them into tensors\n",
    "        self.S = torch.tensor(S_data)\n",
    "        self.I = torch.tensor(I_data)\n",
    "        self.D = torch.tensor(D_data)\n",
    "        self.R = torch.tensor(R_data)\n",
    "\n",
    "        self.losses = [] # here I saved the model's losses per epoch\n",
    "\n",
    "        #setting the parameters\n",
    "        self.alpha_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.beta_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "        self.gamma_tilda = torch.nn.Parameter(torch.rand(1, requires_grad=True))\n",
    "\n",
    "        #find values for normalization\n",
    "        self.S_max = max(self.S)\n",
    "        self.I_max = max(self.I)\n",
    "        self.D_max = max(self.D)\n",
    "        self.R_max = max(self.R)\n",
    "        self.S_min = min(self.S)\n",
    "        self.I_min = min(self.I)\n",
    "        self.D_min = min(self.D)\n",
    "        self.R_min = min(self.R)\n",
    "\n",
    "        #normalize\n",
    "        self.S_hat = (self.S - self.S_min) / (self.S_max - self.S_min)\n",
    "        self.I_hat = (self.I - self.I_min) / (self.I_max - self.I_min)\n",
    "        self.D_hat = (self.D - self.D_min) / (self.D_max - self.D_min)\n",
    "        self.R_hat = (self.R - self.R_min) / (self.R_max - self.R_min)        \n",
    "\n",
    "        #matrices (x4 for S,I,D,R) for the gradients\n",
    "        self.m1 = torch.zeros((len(self.t), 4)); self.m1[:, 0] = 1\n",
    "        self.m2 = torch.zeros((len(self.t), 4)); self.m2[:, 1] = 1\n",
    "        self.m3 = torch.zeros((len(self.t), 4)); self.m3[:, 2] = 1\n",
    "        self.m4 = torch.zeros((len(self.t), 4)); self.m4[:, 3] = 1\n",
    "\n",
    "        #NN\n",
    "        self.net_sidr = self.Net_sidr()\n",
    "        self.params = list(self.net_sidr.parameters())\n",
    "        self.params.extend(list([self.alpha_tilda, self.beta_tilda, self.gamma_tilda]))\n",
    "\n",
    "    #force parameters to be in a range\n",
    "    @property\n",
    "    def alpha(self):\n",
    "        return torch.tanh(self.alpha_tilda) #* 0.1 + 0.2\n",
    "\n",
    "    @property\n",
    "    def beta(self):\n",
    "        return torch.tanh(self.beta_tilda) #* 0.01 + 0.05\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return torch.tanh(self.gamma_tilda) #* 0.01 + 0.03\n",
    "\n",
    "    class Net_sidr(nn.Module): # input = [[t1], [t2]...[t100]] -- that is, a batch of timesteps \n",
    "        def __init__(self):\n",
    "            super(DINN.Net_sidr, self).__init__()\n",
    "\n",
    "            self.fc1=nn.Linear(1, 20) #takes 100 t's\n",
    "            self.fc2=nn.Linear(20, 20)\n",
    "            self.fc3=nn.Linear(20, 20)\n",
    "            self.fc4=nn.Linear(20, 20)\n",
    "            self.fc5=nn.Linear(20, 20)\n",
    "            self.fc6=nn.Linear(20, 20)\n",
    "            self.fc7=nn.Linear(20, 20)\n",
    "            self.fc8=nn.Linear(20, 20)\n",
    "            self.out=nn.Linear(20, 4) #outputs S, I, D, R (100 S, 100 I, 100 D, 100 R --- since we have a batch of 100 timesteps)\n",
    "\n",
    "        def forward(self, t_batch):\n",
    "            sidr=F.relu(self.fc1(t_batch))\n",
    "            sidr=F.relu(self.fc2(sidr))\n",
    "            sidr=F.relu(self.fc3(sidr))\n",
    "            sidr=F.relu(self.fc4(sidr))\n",
    "            sidr=F.relu(self.fc5(sidr))\n",
    "            sidr=F.relu(self.fc6(sidr))\n",
    "            sidr=F.relu(self.fc7(sidr))\n",
    "            sidr=F.relu(self.fc8(sidr))\n",
    "            sidr=self.out(sidr)\n",
    "            return sidr\n",
    "\n",
    "    def net_f(self, t_batch):\n",
    "            \n",
    "            #pass the timesteps batch to the neural network\n",
    "            sidr_hat = self.net_sidr(t_batch)\n",
    "            \n",
    "            #organize S,I,D,R from the neural network's output -- note that these are normalized values -- hence the \"hat\" part\n",
    "            S_hat, I_hat, D_hat, R_hat = sidr_hat[:,0], sidr_hat[:,1], sidr_hat[:,2], sidr_hat[:,3]\n",
    "\n",
    "            #S_t\n",
    "            sidr_hat.backward(self.m1, retain_graph=True)\n",
    "            S_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #I_t\n",
    "            sidr_hat.backward(self.m2, retain_graph=True)\n",
    "            I_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #D_t\n",
    "            sidr_hat.backward(self.m3, retain_graph=True)\n",
    "            D_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_()\n",
    "\n",
    "            #R_t\n",
    "            sidr_hat.backward(self.m4, retain_graph=True)\n",
    "            R_hat_t = self.t.grad.clone()\n",
    "            self.t.grad.zero_() \n",
    "\n",
    "            #unnormalize\n",
    "            S = self.S_min + (self.S_max - self.S_min) * S_hat\n",
    "            I = self.I_min + (self.I_max - self.I_min) * I_hat\n",
    "            D = self.D_min + (self.D_max - self.D_min) * D_hat      \n",
    "            R = self.R_min + (self.R_max - self.R_min) * R_hat        \n",
    "\n",
    "            f1_hat = S_hat_t - (-(self.alpha / self.N) * S * I)  / (self.S_max - self.S_min)\n",
    "            f2_hat = I_hat_t - ((self.alpha / self.N) * S * I - self.beta * I - self.gamma * I ) / (self.I_max - self.I_min)\n",
    "            f3_hat = D_hat_t - (self.gamma * I) / (self.D_max - self.D_min)\n",
    "            f4_hat = R_hat_t - (self.beta * I ) / (self.R_max - self.R_min)        \n",
    "\n",
    "            return f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
    "\n",
    "    def train(self, n_epochs):\n",
    "        # train\n",
    "        print('\\nstarting training...\\n')\n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            # lists to hold the output (maintain only the final epoch)\n",
    "            S_pred_list = []\n",
    "            I_pred_list = []\n",
    "            D_pred_list = []\n",
    "            R_pred_list = []\n",
    "\n",
    "            # we pass the timesteps batch into net_f\n",
    "            f1, f2, f3, f4, S_pred, I_pred, D_pred, R_pred = self.net_f(self.t_batch) # net_f outputs f1_hat, f2_hat, f3_hat, f4_hat, S_hat, I_hat, D_hat, R_hat\n",
    "            \n",
    "            self.optimizer.zero_grad() #zero grad\n",
    "            \n",
    "            #append the values to plot later (note that we unnormalize them here for plotting)\n",
    "            S_pred_list.append(self.S_min + (self.S_max - self.S_min) * S_pred)\n",
    "            I_pred_list.append(self.I_min + (self.I_max - self.I_min) * I_pred)\n",
    "            D_pred_list.append(self.D_min + (self.D_max - self.D_min) * D_pred)\n",
    "            R_pred_list.append(self.R_min + (self.R_max - self.R_min) * R_pred)\n",
    "\n",
    "            #calculate the loss --- MSE of the neural networks output and each compartment\n",
    "            loss = (torch.mean(torch.square(self.S_hat - S_pred))+ \n",
    "                    torch.mean(torch.square(self.I_hat - I_pred))+\n",
    "                    torch.mean(torch.square(self.D_hat - D_pred))+\n",
    "                    torch.mean(torch.square(self.R_hat - R_pred))+\n",
    "                    torch.mean(torch.square(f1))+\n",
    "                    torch.mean(torch.square(f2))+\n",
    "                    torch.mean(torch.square(f3))+\n",
    "                    torch.mean(torch.square(f4))\n",
    "                    ) \n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step() \n",
    "\n",
    "            # append the loss value (we call \"loss.item()\" because we just want the value of the loss and not the entire computational graph)\n",
    "            self.losses.append(loss.item())\n",
    "\n",
    "            if epoch % 1000 == 0:          \n",
    "                print('\\nEpoch ', epoch)\n",
    "\n",
    "                print('alpha: (goal 0.191 ', self.alpha)\n",
    "                print('beta: (goal 0.05 ', self.beta)\n",
    "                print('gamma: (goal 0.0294 ', self.gamma)\n",
    "\n",
    "                print('#################################')                \n",
    "\n",
    "        return S_pred_list, I_pred_list, D_pred_list, R_pred_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96dce0b",
   "metadata": {
    "papermill": {
     "duration": 0.060989,
     "end_time": "2022-04-23T10:24:00.800044",
     "exception": false,
     "start_time": "2022-04-23T10:24:00.739055",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 16. Training the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6078fd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:24:00.927465Z",
     "iopub.status.busy": "2022-04-23T10:24:00.926453Z",
     "iopub.status.idle": "2022-04-23T10:27:57.189849Z",
     "shell.execute_reply": "2022-04-23T10:27:57.190322Z"
    },
    "papermill": {
     "duration": 236.328592,
     "end_time": "2022-04-23T10:27:57.190517",
     "exception": false,
     "start_time": "2022-04-23T10:24:00.861925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting training...\n",
      "\n",
      "\n",
      "Epoch  0\n",
      "alpha: (goal 0.191  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3816], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2541], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  1000\n",
      "alpha: (goal 0.191  tensor([0.0450], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3683], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2397], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  2000\n",
      "alpha: (goal 0.191  tensor([0.0532], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3603], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2310], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  3000\n",
      "alpha: (goal 0.191  tensor([0.0619], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3508], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2208], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  4000\n",
      "alpha: (goal 0.191  tensor([0.0737], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3402], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.2093], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  5000\n",
      "alpha: (goal 0.191  tensor([0.0869], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3289], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1972], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  6000\n",
      "alpha: (goal 0.191  tensor([0.0995], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3182], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1857], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  7000\n",
      "alpha: (goal 0.191  tensor([0.1115], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.3080], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1748], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  8000\n",
      "alpha: (goal 0.191  tensor([0.1233], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2981], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1642], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  9000\n",
      "alpha: (goal 0.191  tensor([0.1333], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2893], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1549], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  10000\n",
      "alpha: (goal 0.191  tensor([0.1431], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2801], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1451], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  11000\n",
      "alpha: (goal 0.191  tensor([0.1538], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2697], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1341], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  12000\n",
      "alpha: (goal 0.191  tensor([0.1653], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2581], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1219], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  13000\n",
      "alpha: (goal 0.191  tensor([0.1760], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2467], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.1100], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  14000\n",
      "alpha: (goal 0.191  tensor([0.1852], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2366], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0995], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  15000\n",
      "alpha: (goal 0.191  tensor([0.1945], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2274], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0900], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  16000\n",
      "alpha: (goal 0.191  tensor([0.2041], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2182], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0805], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  17000\n",
      "alpha: (goal 0.191  tensor([0.2139], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.2087], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0708], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  18000\n",
      "alpha: (goal 0.191  tensor([0.2235], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1991], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0610], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  19000\n",
      "alpha: (goal 0.191  tensor([0.2326], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1896], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0514], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  20000\n",
      "alpha: (goal 0.191  tensor([0.2413], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1803], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0422], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  21000\n",
      "alpha: (goal 0.191  tensor([0.2494], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1715], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0334], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  22000\n",
      "alpha: (goal 0.191  tensor([0.2569], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1630], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0253], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  23000\n",
      "alpha: (goal 0.191  tensor([0.2639], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1550], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0178], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  24000\n",
      "alpha: (goal 0.191  tensor([0.2700], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1473], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0112], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  25000\n",
      "alpha: (goal 0.191  tensor([0.2751], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1402], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0059], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  26000\n",
      "alpha: (goal 0.191  tensor([0.2787], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1334], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0024], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  27000\n",
      "alpha: (goal 0.191  tensor([0.2802], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1270], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0019], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  28000\n",
      "alpha: (goal 0.191  tensor([0.2792], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1203], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0045], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  29000\n",
      "alpha: (goal 0.191  tensor([0.2759], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1130], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0089], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  30000\n",
      "alpha: (goal 0.191  tensor([0.2702], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.1052], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0135], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  31000\n",
      "alpha: (goal 0.191  tensor([0.2619], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0974], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0174], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  32000\n",
      "alpha: (goal 0.191  tensor([0.2537], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0892], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0204], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  33000\n",
      "alpha: (goal 0.191  tensor([0.2446], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0816], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0233], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  34000\n",
      "alpha: (goal 0.191  tensor([0.2354], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0745], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0257], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  35000\n",
      "alpha: (goal 0.191  tensor([0.2261], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0680], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0275], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  36000\n",
      "alpha: (goal 0.191  tensor([0.2172], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0625], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0289], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  37000\n",
      "alpha: (goal 0.191  tensor([0.2089], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0582], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0294], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  38000\n",
      "alpha: (goal 0.191  tensor([0.2017], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0551], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0297], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  39000\n",
      "alpha: (goal 0.191  tensor([0.1961], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0530], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0295], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  40000\n",
      "alpha: (goal 0.191  tensor([0.1926], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0517], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0293], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  41000\n",
      "alpha: (goal 0.191  tensor([0.1907], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0513], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0291], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  42000\n",
      "alpha: (goal 0.191  tensor([0.1903], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0512], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0291], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  43000\n",
      "alpha: (goal 0.191  tensor([0.1902], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0513], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  44000\n",
      "alpha: (goal 0.191  tensor([0.1906], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0513], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  45000\n",
      "alpha: (goal 0.191  tensor([0.1910], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0513], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0293], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  46000\n",
      "alpha: (goal 0.191  tensor([0.1910], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0515], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  47000\n",
      "alpha: (goal 0.191  tensor([0.1914], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0512], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0291], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  48000\n",
      "alpha: (goal 0.191  tensor([0.1912], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0516], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "\n",
      "Epoch  49000\n",
      "alpha: (goal 0.191  tensor([0.1910], grad_fn=<TanhBackward>)\n",
      "beta: (goal 0.05  tensor([0.0515], grad_fn=<TanhBackward>)\n",
      "gamma: (goal 0.0294  tensor([0.0290], grad_fn=<TanhBackward>)\n",
      "#################################\n",
      "CPU times: user 3min 55s, sys: 122 ms, total: 3min 56s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dinn = DINN(covid_data[0], covid_data[1], covid_data[2], covid_data[3], \n",
    "            covid_data[4]) #in the form of [t,S,I,D,R]\n",
    "\n",
    "learning_rate = 1e-6\n",
    "optimizer = optim.Adam(dinn.params, lr = learning_rate)\n",
    "dinn.optimizer = optimizer\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(dinn.optimizer, base_lr=1e-5, max_lr=1e-3, step_size_up=1000, mode=\"exp_range\", gamma=0.85, cycle_momentum=False)\n",
    "\n",
    "dinn.scheduler = scheduler\n",
    "\n",
    "S_pred_list, I_pred_list, D_pred_list, R_pred_list = dinn.train(50000) #train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e033c13",
   "metadata": {
    "papermill": {
     "duration": 0.080327,
     "end_time": "2022-04-23T10:27:57.351937",
     "exception": false,
     "start_time": "2022-04-23T10:27:57.271610",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 17. Plotting the losses and values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1deea8ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:27:57.535168Z",
     "iopub.status.busy": "2022-04-23T10:27:57.534499Z",
     "iopub.status.idle": "2022-04-23T10:27:57.695045Z",
     "shell.execute_reply": "2022-04-23T10:27:57.694503Z"
    },
    "papermill": {
     "duration": 0.263137,
     "end_time": "2022-04-23T10:27:57.695178",
     "exception": false,
     "start_time": "2022-04-23T10:27:57.432041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text(0, 0.5, 'Loss'),)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dinn.losses[0:], color = 'teal')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss'),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d402b54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-23T10:27:58.012345Z",
     "iopub.status.busy": "2022-04-23T10:27:57.873003Z",
     "iopub.status.idle": "2022-04-23T10:27:58.281146Z",
     "shell.execute_reply": "2022-04-23T10:27:58.281670Z"
    },
    "papermill": {
     "duration": 0.505091,
     "end_time": "2022-04-23T10:27:58.281841",
     "exception": false,
     "start_time": "2022-04-23T10:27:57.776750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:22: MatplotlibDeprecationWarning: The 'b' parameter of grid() has been renamed 'visible' since Matplotlib 3.5; support for the old name will be dropped two minor releases later.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(111, facecolor='#dddddd', axisbelow=True)\n",
    "ax.set_facecolor('xkcd:white')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[1], 'pink', alpha=0.5, lw=2, label='Susceptible')\n",
    "ax.plot(covid_data[0], S_pred_list[0].detach().numpy(), 'red', alpha=0.9, lw=2, label='Susceptible Prediction', linestyle='dashed')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[2], 'violet', alpha=0.5, lw=2, label='Infected')\n",
    "ax.plot(covid_data[0], I_pred_list[0].detach().numpy(), 'dodgerblue', alpha=0.9, lw=2, label='Infected Prediction', linestyle='dashed')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[3], 'darkgreen', alpha=0.5, lw=2, label='Dead')\n",
    "ax.plot(covid_data[0], D_pred_list[0].detach().numpy(), 'green', alpha=0.9, lw=2, label='Dead Prediction', linestyle='dashed')\n",
    "\n",
    "ax.plot(covid_data[0], covid_data[4], 'blue', alpha=0.5, lw=2, label='Recovered')\n",
    "ax.plot(covid_data[0], R_pred_list[0].detach().numpy(), 'teal', alpha=0.9, lw=2, label='Recovered Prediction', linestyle='dashed')\n",
    "\n",
    "\n",
    "ax.set_xlabel('Time /days')\n",
    "ax.set_ylabel('Number')\n",
    "ax.yaxis.set_tick_params(length=0)\n",
    "ax.xaxis.set_tick_params(length=0)\n",
    "ax.grid(b=True, which='major', c='black', lw=0.2, ls='-')\n",
    "legend = ax.legend()\n",
    "legend.get_frame().set_alpha(0.5)\n",
    "for spine in ('top', 'right', 'bottom', 'left'):\n",
    "    ax.spines[spine].set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e20654",
   "metadata": {
    "papermill": {
     "duration": 0.084984,
     "end_time": "2022-04-23T10:27:58.451977",
     "exception": false,
     "start_time": "2022-04-23T10:27:58.366993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**This is the end of this notebook, go to ... to have more infromation.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 258.657081,
   "end_time": "2022-04-23T10:27:59.349090",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-04-23T10:23:40.692009",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
